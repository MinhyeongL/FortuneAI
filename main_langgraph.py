"""
FortuneAI LangGraph ì‹œìŠ¤í…œ ë©”ì¸ ì‹¤í–‰ íŒŒì¼
Supervisor íŒ¨í„´ ê¸°ë°˜ ì‚¬ì£¼ ê³„ì‚°ê¸°
"""

import os
import sys
import time
import uuid
import logging

# httpx ë¡œê¹… ë¹„í™œì„±í™” (OpenAI API í˜¸ì¶œ ë¡œê·¸ ìˆ¨ê¹€)
logging.getLogger("httpx").setLevel(logging.WARNING)

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from langchain_core.messages import HumanMessage
from langgraph_system.graph import create_workflow

# ìƒˆë¡œ ë¶„ë¦¬í•œ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆë“¤ import
from utils import (
    print_banner, 
    print_system_info, 
    format_response, 
    print_help,
    handle_debug_query,
    handle_verbose_query, 
    handle_stream_query,
    run_query_with_app
)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print_banner()
    print_system_info()
    
    # âœ¨ ì‹œìŠ¤í…œ ì‹œì‘ ì‹œ NodeManager ë¯¸ë¦¬ ì´ˆê¸°í™”
    print("ğŸ”§ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    from langgraph_system.nodes import get_node_manager
    get_node_manager()  # ì‹±ê¸€í†¤ ì´ˆê¸°í™” (6-10ì´ˆ ì†Œìš”)
    print("âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
    
    # âœ¨ ì›Œí¬í”Œë¡œë„ ë¯¸ë¦¬ ìƒì„±
    print("âš™ï¸ ì›Œí¬í”Œë¡œ ìƒì„± ì¤‘...")
    app = create_workflow()
    print("âœ… ì›Œí¬í”Œë¡œ ì¤€ë¹„ ì™„ë£Œ!")
    
    session_id = f"session_{int(time.time())}"
    query_count = 0
    conversation_history = []  # ğŸ”¥ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    
    print("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš” (ì¢…ë£Œ: quit/exit):")
    
    while True:
        try:
            # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
            user_input = input("\nğŸ¤” ì§ˆë¬¸: ").strip()
            
            # ì¢…ë£Œ ëª…ë ¹ ì²˜ë¦¬
            if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:
                print("\nğŸ‘‹ FortuneAIë¥¼ ì´ìš©í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!")
                print("ğŸŒŸ ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”! ğŸŒŸ")
                break
            
            # ìƒˆ ì„¸ì…˜ ì‹œì‘ ëª…ë ¹ ì²˜ë¦¬
            if user_input.lower() in ['new', 'clear']:
                session_id = str(uuid.uuid4())
                query_count = 0
                conversation_history = []  # ğŸ”¥ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
                print(f"\nğŸ”„ ìƒˆë¡œìš´ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. (ì„¸ì…˜ ID: {session_id[:8]}...)")
                
                # í™˜ì˜ ë©”ì‹œì§€ ìƒì„±
                welcome_response = run_query_with_app("ì•ˆë…•í•˜ì„¸ìš”! FortuneAIì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?", app, conversation_history)
                print(f"ğŸ”® FortuneAI: {welcome_response}")
                print("-" * 60)
                continue
            
            # ë„ì›€ë§ ëª…ë ¹ ì²˜ë¦¬
            if user_input.lower() in ['help', 'h', 'ë„ì›€ë§', '?']:
                print_help()
                continue
            
            # ë¹ˆ ì…ë ¥ ì²˜ë¦¬
            if not user_input:
                print("â“ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue
            
            query_count += 1
            print(f"\nâ³ ë¶„ì„ ì¤‘... (ì§ˆë¬¸ #{query_count})")
            
            # ë””ë²„ê·¸ ëª¨ë“œ ì²˜ë¦¬
            if user_input.startswith("debug:"):
                response = handle_debug_query(user_input, app, conversation_history)
                print(response)
                continue
            
            # ìƒì„¸ ëª¨ë“œ ì²˜ë¦¬
            if user_input.startswith("verbose:"):
                response = handle_verbose_query(user_input, app, conversation_history)
                print(f"\nğŸ“ **ìµœì¢… ì‘ë‹µ**\n{format_response(response)}")
                continue
            
            # ìŠ¤íŠ¸ë¦¬ë° ì¿¼ë¦¬ ì²˜ë¦¬
            if user_input.startswith("stream:"):
                response = handle_stream_query(user_input, app, conversation_history)
                print(f"\nğŸ“ **ìµœì¢… ì‘ë‹µ**\n{format_response(response)}")
                continue
            
            # ì¼ë°˜ ì¿¼ë¦¬ ì‹¤í–‰ - ë¯¸ë¦¬ ìƒì„±ëœ ì›Œí¬í”Œë¡œ ì‚¬ìš©
            start_time = time.time()
            response = run_query_with_app(user_input, app, conversation_history)  # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì „ë‹¬
            execution_time = time.time() - start_time
            
            # ì‘ë‹µ ì¶œë ¥
            formatted_response = format_response(response)
            print(formatted_response)
            
            # ì‹¤í–‰ ì‹œê°„ í‘œì‹œ
            print(f"\nâ±ï¸  ì‹¤í–‰ ì‹œê°„: {execution_time:.2f}ì´ˆ")
            
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
            print("ğŸ‘‹ FortuneAIë¥¼ ì´ìš©í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!")
            break
            
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            print("ğŸ”§ ì‹œìŠ¤í…œì„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")
            continue


if __name__ == "__main__":
    # ëª…ë ¹í–‰ ì¸ì ì²˜ë¦¬
    if len(sys.argv) > 1:
        if sys.argv[1] == "debug":
            if len(sys.argv) > 2:
                query = " ".join(sys.argv[2:])
                # ëª…ë ¹í–‰ì—ì„œëŠ” ì›Œí¬í”Œë¡œë¥¼ ìƒˆë¡œ ìƒì„±
                print("ğŸ”§ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
                from langgraph_system.nodes import get_node_manager
                get_node_manager()
                print("âš™ï¸ ì›Œí¬í”Œë¡œ ìƒì„± ì¤‘...")
                app = create_workflow()
                conversation_history = []
                result = handle_debug_query(f"debug:{query}", app, conversation_history)
                print(result)
            else:
                print("âŒ ë””ë²„ê·¸í•  ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                print("ğŸ’¡ ì‚¬ìš©ë²•: python main_langgraph.py debug \"1995ë…„ 8ì›” 26ì¼ ì‚¬ì£¼\"")
        else:
            print("âŒ ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì…ë‹ˆë‹¤.")
            print("ğŸ’¡ ì‚¬ìš©ë²•: python main_langgraph.py [debug \"ì§ˆë¬¸\"]")
    else:
        main() 